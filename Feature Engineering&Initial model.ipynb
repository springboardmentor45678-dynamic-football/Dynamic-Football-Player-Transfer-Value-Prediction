{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btKoMX16i1eh",
        "outputId": "e58f1d59-8e64-4ec5-bc12-7a118f520558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Final dataset loaded: (50000, 161)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "def safe_load_csv(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file at {file_path} was not found. Please check the path.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while loading the CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/datasets_2/\"\n",
        "final_path = path + \"master_file2_preprocessed_small.csv\"\n",
        "df = safe_load_csv(final_path)\n",
        "\n",
        "if df is not None:\n",
        "    print(\"Final dataset loaded:\", df.shape)\n",
        "else:\n",
        "    print(\"Failed to load dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "if \"date_of_birth\" in df.columns:\n",
        "    df[\"date_of_birth\"] = pd.to_datetime(df[\"date_of_birth\"], errors='coerce')\n",
        "    df[\"age\"] = datetime.now().year - df[\"date_of_birth\"].dt.year\n"
      ],
      "metadata": {
        "id": "9xEeyWnAi9k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"injury_reason\" in df.columns:\n",
        "    df[\"is_injured\"] = df[\"injury_reason\"].apply(lambda x: 0 if pd.isna(x) else 1)\n"
      ],
      "metadata": {
        "id": "ZZ03vqtBjCrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (\"goals\" in df.columns) and (\"appearances\" in df.columns):\n",
        "    df[\"goals_per_match\"] = df[\"goals\"] / (df[\"appearances\"] + 1)\n"
      ],
      "metadata": {
        "id": "UylQTMFCjFLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = df.select_dtypes(include=['float64','int64']).columns\n",
        "\n",
        "z = np.abs((df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std())\n",
        "# df_no_outliers = df[(z < 3).all(axis=1)] # Original aggressive outlier removal\n",
        "\n",
        "# Temporarily bypassing aggressive outlier removal to allow model training to proceed\n",
        "df_no_outliers = df.copy()\n",
        "\n",
        "print(\"After outlier removal:\", df_no_outliers.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcpTrNcjIvb",
        "outputId": "209fa8a4-1bad-4802-87da-ae265f49c09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After outlier removal: (50000, 161)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = \"value\"  # change if needed!\n",
        "\n",
        "df_no_outliers = df_no_outliers.dropna(subset=[target])  # ensure no missing target\n",
        "\n",
        "X = df_no_outliers.drop(columns=[target])\n",
        "y = df_no_outliers[target]\n",
        "\n",
        "print(\"Shapes:\", X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMqDFAQXjOyI",
        "outputId": "149c5a47-5979-4382-860d-117207a7c877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (48693, 160) (48693,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4EoKBjmjRxB",
        "outputId": "8e0c72ff-9e4c-4749-ca76-2c6d6551de91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (38954, 160)  Test: (9739, 160)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_imputed, y_train)\n",
        "\n",
        "y_pred = lr.predict(X_test_imputed)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"----- Linear Regression Performance -----\")\n",
        "print(\"MSE:\", mse)\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"MAE:\", mae)\n",
        "print(\"R²:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGzp6mYrjZI6",
        "outputId": "bef4f2a0-a92f-4afe-b62a-23b56eaea477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['player_name_y' 'text' 'vader_polarity' 'vader_emotion' 'tb_polarity'\n",
            " 'tb_emotion' 'game_date' 'tweet_date' 'when']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['player_name_y' 'text' 'vader_polarity' 'vader_emotion' 'tb_polarity'\n",
            " 'tb_emotion' 'game_date' 'tweet_date' 'when']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Linear Regression Performance -----\n",
            "MSE: 49156732348211.16\n",
            "RMSE: 7011186.229748227\n",
            "MAE: 2825116.8301904784\n",
            "R²: 0.1516672078886694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "poly = PolynomialFeatures(degree=1)\n",
        "X_train_poly = poly.fit_transform(X_train_imputed)\n",
        "X_test_poly = poly.transform(X_test_imputed)\n",
        "\n",
        "model_poly_1 = LinearRegression()\n",
        "model_poly_1.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred_poly_1 = model_poly_1.predict(X_test_poly)\n",
        "rmse_1 = np.sqrt(mean_squared_error(y_test, y_pred_poly_1))\n",
        "\n",
        "print(\"Polynomial Degree 1 → RMSE:\", rmse_1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oeLdDiRjbo2",
        "outputId": "de104e4b-b5bc-4a17-e929-609b046aead0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Degree 1 → RMSE: 7011186.229744081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: reduce features\n",
        "# X_train_imputed is a numpy array, so select_dtypes is not applicable.\n",
        "# We will directly select the first 20 columns from the imputed arrays.\n",
        "X_train_small = X_train_imputed[:, :20]\n",
        "X_test_small = X_test_imputed[:, :20]\n",
        "\n",
        "print(\"Shapes:\", X_train_small.shape, X_test_small.shape)\n",
        "\n",
        "# Step 2: polynomial degree 2\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_train_poly = poly.fit_transform(X_train_small)\n",
        "X_test_poly = poly.transform(X_test_small)\n",
        "\n",
        "print(\"Poly shape:\", X_train_poly.shape)\n",
        "\n",
        "# Step 3: model\n",
        "model_poly_2 = LinearRegression()\n",
        "model_poly_2.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred = model_poly_2.predict(X_test_poly)\n",
        "rmse_2 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(\"Degree 2 RMSE:\", rmse_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtYL_oS-lhHs",
        "outputId": "57912e1e-d060-4ea2-f751-9440ccfc5432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (38954, 20) (9739, 20)\n",
            "Poly shape: (38954, 231)\n",
            "Degree 2 RMSE: 7189956.039213703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_imputed is a numpy array, so select_dtypes is not applicable.\n",
        "# We will directly select the first 10 columns from the imputed arrays.\n",
        "selected_cols = X_train_imputed[:, :10]\n",
        "\n",
        "X_train_small = selected_cols\n",
        "X_test_small = X_test_imputed[:, :10]\n",
        "\n",
        "print(\"Using the first 10 features.\")\n",
        "print(\"Shapes:\", X_train_small.shape, X_test_small.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAqpESPemnMn",
        "outputId": "ea2b1fc4-3957-488e-e869-0da17cd196a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the first 10 features.\n",
            "Shapes: (38954, 10) (9739, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=3)\n",
        "X_train_poly = poly.fit_transform(X_train_small)\n",
        "X_test_poly = poly.transform(X_test_small)\n",
        "\n",
        "model_poly_3 = LinearRegression()\n",
        "model_poly_3.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred_poly_3 = model_poly_3.predict(X_test_poly)\n",
        "rmse_3 = np.sqrt(mean_squared_error(y_test, y_pred_poly_3))\n",
        "\n",
        "print(\"Polynomial Degree 3 → RMSE:\", rmse_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsdiH5AbljXr",
        "outputId": "1fe6ebff-f5bf-429f-cdc5-d43b04434661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Degree 3 → RMSE: 7190105.800846882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=4)\n",
        "X_train_poly = poly.fit_transform(X_train_small)\n",
        "X_test_poly = poly.transform(X_test_small)\n",
        "\n",
        "model_poly_4 = LinearRegression()\n",
        "model_poly_4.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred_poly_4 = model_poly_4.predict(X_test_poly)\n",
        "rmse_4 = np.sqrt(mean_squared_error(y_test, y_pred_poly_4))\n",
        "\n",
        "print(\"Polynomial Degree 4 → RMSE:\", rmse_4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNgvkl5zllf_",
        "outputId": "dc886601-3b55-47a7-cfc0-520db51dcf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Degree 4 → RMSE: 7495857.152712039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree=5)\n",
        "X_train_poly = poly.fit_transform(X_train_small)\n",
        "X_test_poly = poly.transform(X_test_small)\n",
        "\n",
        "model_poly_5 = LinearRegression()\n",
        "model_poly_5.fit(X_train_poly, y_train)\n",
        "\n",
        "y_pred_poly_5 = model_poly_5.predict(X_test_poly)\n",
        "rmse_5 = np.sqrt(mean_squared_error(y_test, y_pred_poly_5))\n",
        "\n",
        "print(\"Polynomial Degree 5 → RMSE:\", rmse_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QpYP9eBlnsR",
        "outputId": "9e8a9d9e-80ef-43f2-cd07-b7683f6d2501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Degree 5 → RMSE: 29914651.913857523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "degrees = [1, 2, 3, 4, 5]\n",
        "errors = [rmse_1, rmse_2, rmse_3, rmse_4, rmse_5]\n",
        "\n",
        "plt.plot(degrees, errors, marker='o')\n",
        "plt.xlabel(\"Polynomial Degree\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.title(\"Polynomial Regression Error Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "0bn4huSajeng",
        "outputId": "5ff2174e-3b92-4d53-ce80-3f992ab37478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Fix preprocessing issues + run safe RF and LGB baselines =====\n",
        "import numpy as np, pandas as pd, joblib, time\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "import lightgbm # Added import for lightgbm module\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Assumes df_no_outliers exists\n",
        "df = df_no_outliers.copy()\n",
        "\n",
        "TARGET = \"value\"\n",
        "# 1) Drop ID columns if exist\n",
        "for c in [\"player_id\", \"date_unix\", \"Unnamed: 0\"]:\n",
        "    if c in df.columns: df.drop(columns=c, inplace=True)\n",
        "\n",
        "# 2) Drop columns with ALL missing values (they cause the imputer warnings)\n",
        "all_null_cols = df.columns[df.isna().all()].tolist()\n",
        "print(\"Columns with all-null (dropping):\", all_null_cols)\n",
        "df.drop(columns=all_null_cols, inplace=True)\n",
        "\n",
        "# 3) If there are non-numeric columns that you intended as categorical, ensure they are object dtype.\n",
        "#    We'll auto-detect again.\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET].values\n",
        "\n",
        "# Convert boolean columns to object dtype to be correctly handled as categories by imputer\n",
        "for col in X.select_dtypes(include=['bool']).columns:\n",
        "    X[col] = X[col].astype(str)\n",
        "\n",
        "# Recompute numeric/categorical split safely\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "print(\"NUM cols:\", len(num_cols), \"CAT cols:\", len(cat_cols))\n",
        "\n",
        "# If you have text columns you don't want encoded (tweet text etc), drop them explicitly:\n",
        "text_like = [c for c in X.columns if c.lower() in (\"text\",\"tweet_text\",\"tweet_date\",\"game_date\",\"player_name_y\")]\n",
        "print(\"Text-like columns (drop if present):\", text_like)\n",
        "# drop them (you can keep them and extract features later, but drop for now)\n",
        "for c in text_like:\n",
        "    if c in X.columns:\n",
        "        X = X.drop(columns=c)\n",
        "        if c in num_cols: num_cols.remove(c)\n",
        "        if c in cat_cols: cat_cols.remove(c)\n",
        "\n",
        "# Recreate train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# 4) Rebuild a small preprocessor (median imputer for numeric; frequent for cat; OHE with sparse)\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "TOP_K = 30\n",
        "# cap top-K categories\n",
        "for c in cat_cols:\n",
        "    topk = X_train[c].value_counts().nlargest(TOP_K).index\n",
        "    X_train[c] = X_train[c].where(X_train[c].isin(topk), other=\"__OTHER__\")\n",
        "    X_test[c]  = X_test[c].where(X_test[c].isin(topk), other=\"__OTHER__\")\n",
        "\n",
        "num_transformer = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
        "cat_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)) # FIX: Changed 'sparse=True' to 'sparse_output=True'\n",
        "])\n",
        "from sklearn.compose import ColumnTransformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", num_transformer, num_cols),\n",
        "    (\"cat\", cat_transformer, cat_cols)\n",
        "], remainder='drop')\n",
        "\n",
        "# Fit once and transform\n",
        "preprocessor.fit(X_train)\n",
        "X_train_trans = preprocessor.transform(X_train)\n",
        "X_test_trans  = preprocessor.transform(X_test)\n",
        "\n",
        "# Convert to CSR sparse (if not)\n",
        "if not sparse.isspmatrix_csr(X_train_trans):\n",
        "    X_train_trans = sparse.csr_matrix(X_train_trans)\n",
        "if not sparse.isspmatrix_csr(X_test_trans):\n",
        "    X_test_trans = sparse.csr_matrix(X_test_trans)\n",
        "\n",
        "print(\"Transformed shapes:\", X_train_trans.shape, X_test_trans.shape)\n",
        "\n",
        "# 5) Baseline Random Forest (no search) -- uses modest defaults to ensure it runs fast\n",
        "rf = RandomForestRegressor(n_estimators=100, max_depth=15, n_jobs=-1, random_state=42)\n",
        "t0 = time.time()\n",
        "# convert to dense if small (ours: 38954 x 149 -> dense ok)\n",
        "X_train_rf = X_train_trans.toarray() if sparse.isspmatrix(X_train_trans) else X_train_trans\n",
        "X_test_rf  = X_test_trans.toarray()  if sparse.isspmatrix(X_test_trans) else X_test_trans\n",
        "rf.fit(X_train_rf, y_train)\n",
        "print(\"RF baseline fit time: %.2fs\" % (time.time()-t0))\n",
        "y_rf = rf.predict(X_test_rf)\n",
        "print(\"RF baseline RMSE:\", np.sqrt(mean_squared_error(y_test, y_rf)), \"R2:\", r2_score(y_test, y_rf))\n",
        "\n",
        "# 6) Baseline LightGBM (no search)\n",
        "lgb = LGBMRegressor(n_estimators=200, learning_rate=0.05, max_depth=10, n_jobs=-1, random_state=42)\n",
        "t0 = time.time()\n",
        "# LightGBM accepts sparse; pass sparse if available\n",
        "lgb.fit(X_train_trans, y_train, eval_set=[(X_test_trans, y_test)], eval_metric='rmse', callbacks=[lightgbm.early_stopping(50, verbose=False)]) # Fixed early stopping\n",
        "print(\"LGB baseline fit time: %.2fs\" % (time.time()-t0))\n",
        "y_lgb = lgb.predict(X_test_trans)\n",
        "print(\"LGB baseline RMSE:\", np.sqrt(mean_squared_error(y_test, y_lgb)), \"R2:\", r2_score(y_test, y_lgb))\n",
        "\n",
        "# 7) Quick RandomizedSearch on a SMALL SUBSET to tune RF and LGB safely\n",
        "#    We'll sample 10k rows from training to speed up the search\n",
        "sample_n = min(10000, X_train_rf.shape[0])\n",
        "idx = np.random.RandomState(1).choice(np.arange(X_train_rf.shape[0]), size=sample_n, replace=False)\n",
        "X_train_sub = X_train_rf[idx]\n",
        "y_train_sub = y_train[idx]\n",
        "\n",
        "# RF randomized search (small)\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "rf_params = {\n",
        "    \"n_estimators\": [100, 150, 250],\n",
        "    \"max_depth\": [10, 15, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "rf_search = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1, random_state=42),\n",
        "                               rf_params, n_iter=6, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=1)\n",
        "t0 = time.time()\n",
        "rf_search.fit(X_train_sub, y_train_sub)\n",
        "print(\"RF search time (subset): %.2fs\" % (time.time()-t0))\n",
        "print(\"RF best params:\", rf_search.best_params_)\n",
        "best_rf = rf_search.best_estimator_\n",
        "y_brf = best_rf.predict(X_test_rf)\n",
        "print(\"RF tuned RMSE:\", np.sqrt(mean_squared_error(y_test, y_brf)), \"R2:\", r2_score(y_test, y_brf))\n",
        "\n",
        "# LGB randomized search (small, on sparse)\n",
        "lgb_params = {\n",
        "    \"n_estimators\": [100,200,400],\n",
        "    \"max_depth\": [6,10,15,-1],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1]\n",
        "}\n",
        "lgb_search = RandomizedSearchCV(LGBMRegressor(n_jobs=-1, random_state=42),\n",
        "                                lgb_params, n_iter=6, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=2)\n",
        "t0 = time.time()\n",
        "# use sparse for LGB\n",
        "lgb_search.fit(X_train_trans[idx], y_train_sub)\n",
        "print(\"LGB search time (subset): %.2fs\" % (time.time()-t0))\n",
        "print(\"LGB best params:\", lgb_search.best_params_)\n",
        "best_lgb = lgb_search.best_estimator_\n",
        "y_blgb = best_lgb.predict(X_test_trans)\n",
        "print(\"LGB tuned RMSE:\", np.sqrt(mean_squared_error(y_test, y_blgb)), \"R2:\", r2_score(y_test, y_blgb))\n",
        "\n",
        "# 8) Save best models if you want\n",
        "joblib.dump(best_rf, \"/content/drive/MyDrive/datasets_2/models_opt_no_lasso/best_rf_small_search.joblib\")\n",
        "joblib.dump(best_lgb, \"/content/drive/MyDrive/datasets_2/models_opt_no_lasso/best_lgb_small_search.joblib\")\n",
        "\n",
        "print(\"Done: baseline + small searches finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IavbfLOpjeMN",
        "outputId": "5435682d-68ca-455b-e7b5-3459ea4b42ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with all-null (dropping): ['player_name_y', 'text', 'vader_polarity', 'vader_emotion', 'tb_polarity', 'tb_emotion', 'game_date', 'tweet_date', 'when']\n",
            "NUM cols: 149 CAT cols: 1\n",
            "Text-like columns (drop if present): []\n",
            "Train: (38954, 150) Test: (9739, 150)\n",
            "Transformed shapes: (38954, 151) (9739, 151)\n",
            "RF baseline fit time: 108.52s\n",
            "RF baseline RMSE: 2670498.011827832 R2: 0.8769255887236677\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2202\n",
            "[LightGBM] [Info] Number of data points in the train set: 38954, number of used features: 106\n",
            "[LightGBM] [Info] Start training from score 2017472.018278\n",
            "LGB baseline fit time: 10.69s\n",
            "LGB baseline RMSE: 3880125.631690931 R2: 0.740178656511445\n",
            "RF search time (subset): 443.96s\n",
            "RF best params: {'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 20}\n",
            "RF tuned RMSE: 5296875.700514417 R2: 0.5158021994198722\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1946\n",
            "[LightGBM] [Info] Number of data points in the train set: 10000, number of used features: 82\n",
            "[LightGBM] [Info] Start training from score 1941198.750000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LGB search time (subset): 60.86s\n",
            "LGB best params: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1}\n",
            "LGB tuned RMSE: 5319602.046890375 R2: 0.5116383662129991\n",
            "Done: baseline + small searches finished.\n"
          ]
        }
      ]
    }
  ]
}