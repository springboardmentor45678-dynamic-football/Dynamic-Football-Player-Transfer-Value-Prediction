{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3b322d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING FINAL DATA PREP (V3 KAGGLE) ---\n",
      "\n",
      "Processing 1: Market Values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_16032\\271970903.py:14: DtypeWarning: Columns (29,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_profiles = pd.read_csv('player_profiles.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> DONE. Saved '1_master_market_values.csv' with 901429 rows.\n",
      "\n",
      "Processing 2: Player Performance...\n",
      "-> DONE. Saved '2_master_performance.csv' with 1878719 rows.\n",
      "\n",
      "Processing 3: Injury History...\n",
      "-> DONE. Saved '3_master_injuries.csv' with 143195 rows.\n",
      "\n",
      "Processing 4: Social Sentiment...\n",
      "   (Calculating sentiment...)\n",
      "-> DONE. Saved '4_master_sentiment.csv' with 521 rows.\n",
      "\n",
      "--- ALL MASTER FILES READY ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "print(\"--- STARTING FINAL DATA PREP (V3 KAGGLE) ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. CREATE TARGET FILE (Market Values)\n",
    "# ==========================================\n",
    "print(\"\\nProcessing 1: Market Values...\")\n",
    "try:\n",
    "    # Load files\n",
    "    df_values = pd.read_csv('player_market_value.csv')\n",
    "    df_profiles = pd.read_csv('player_profiles.csv')\n",
    "\n",
    "    # RENAME columns to standard format if they differ\n",
    "    df_values.rename(columns={'value': 'market_value', 'date_unix': 'date'}, inplace=True)\n",
    "    df_profiles.rename(columns={'name': 'player_name', 'country': 'country_of_birth'}, inplace=True)\n",
    "\n",
    "    # Merge to link Names to Values\n",
    "    # We use 'player_id' as the key\n",
    "    df_target = pd.merge(df_values, \n",
    "                         df_profiles[['player_id', 'player_name', 'position', 'date_of_birth', 'country_of_birth']], \n",
    "                         on='player_id', \n",
    "                         how='inner') # Use inner to only keep players we have info for\n",
    "\n",
    "    # Clean Dates\n",
    "    df_target['date'] = pd.to_datetime(df_target['date'])\n",
    "    df_target = df_target.sort_values(['player_id', 'date'])\n",
    "\n",
    "    # Save\n",
    "    df_target.to_csv('1_master_market_values.csv', index=False)\n",
    "    print(f\"-> DONE. Saved '1_master_market_values.csv' with {len(df_target)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"-> ERROR in File 1: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. CREATE PERFORMANCE FILE (Stats)\n",
    "# ==========================================\n",
    "print(\"\\nProcessing 2: Player Performance...\")\n",
    "try:\n",
    "    df_perf = pd.read_csv('player_performances.csv')\n",
    "    \n",
    "    # Select only the columns we need for the AI\n",
    "    cols_needed = ['player_id', 'game_id', 'goals', 'assists', 'minutes_played', 'yellow_cards', 'red_cards']\n",
    "    \n",
    "    # Filter columns that actually exist in the file\n",
    "    existing_cols = [c for c in cols_needed if c in df_perf.columns]\n",
    "    df_perf = df_perf[existing_cols]\n",
    "\n",
    "    # Save\n",
    "    df_perf.to_csv('2_master_performance.csv', index=False)\n",
    "    print(f\"-> DONE. Saved '2_master_performance.csv' with {len(df_perf)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"-> ERROR in File 2: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. CREATE INJURY FILE\n",
    "# ==========================================\n",
    "print(\"\\nProcessing 3: Injury History...\")\n",
    "try:\n",
    "    df_injuries = pd.read_csv('player_injuries.csv')\n",
    "    \n",
    "    # Standardize column names based on your screenshot\n",
    "    df_injuries.rename(columns={\n",
    "        'from_date': 'injury_date', \n",
    "        'end_date': 'recovery_date',\n",
    "        'injury': 'injury_type'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Calculate duration if missing\n",
    "    if 'days_missed' not in df_injuries.columns:\n",
    "        df_injuries['injury_date'] = pd.to_datetime(df_injuries['injury_date'])\n",
    "        df_injuries['recovery_date'] = pd.to_datetime(df_injuries['recovery_date'])\n",
    "        df_injuries['days_missed'] = (df_injuries['recovery_date'] - df_injuries['injury_date']).dt.days\n",
    "\n",
    "    df_injuries.to_csv('3_master_injuries.csv', index=False)\n",
    "    print(f\"-> DONE. Saved '3_master_injuries.csv' with {len(df_injuries)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"-> ERROR in File 3: {e}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. CREATE SENTIMENT FILE (Tweets)\n",
    "# ==========================================\n",
    "print(\"\\nProcessing 4: Social Sentiment...\")\n",
    "try:\n",
    "    # Load your excel file (or csv if you converted it)\n",
    "    # NOTE: Adjust filename if yours is .xlsx or .csv\n",
    "    df_tweets = pd.read_csv('tweets_premier_league_footballers.csv', encoding='latin1')\n",
    "\n",
    "    # Fix Column Names (from your previous screenshot)\n",
    "    df_tweets.rename(columns={'player_na': 'player_name', 'text': 'tweet_text'}, inplace=True)\n",
    "    \n",
    "    # Fallback search for text column\n",
    "    if 'tweet_text' not in df_tweets.columns:\n",
    "         df_tweets['tweet_text'] = df_tweets.iloc[:, 1] \n",
    "\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text.lower().strip()\n",
    "\n",
    "    print(\"   (Calculating sentiment...)\")\n",
    "    df_tweets['clean_text'] = df_tweets['tweet_text'].apply(clean_text)\n",
    "    df_tweets['sentiment'] = df_tweets['clean_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "    # Aggregate\n",
    "    df_sentiment = df_tweets.groupby('player_name')['sentiment'].mean().reset_index()\n",
    "    \n",
    "    df_sentiment.to_csv('4_master_sentiment.csv', index=False)\n",
    "    print(f\"-> DONE. Saved '4_master_sentiment.csv' with {len(df_sentiment)} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"-> ERROR in File 4: {e}\")\n",
    "\n",
    "print(\"\\n--- ALL MASTER FILES READY ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb72ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET REPORT GENERATOR ===\n",
      "\n",
      "1. MARKET VALUES DATA\n",
      "   - Total Records: 901,429\n",
      "   - Unique Players: 69,441\n",
      "   - Date Range: 2003-12-14 to 2025-09-11\n",
      "   - Missing Values:\n",
      "player_id               0\n",
      "date                    0\n",
      "market_value            0\n",
      "player_name          4234\n",
      "position                0\n",
      "date_of_birth        1861\n",
      "country_of_birth    38318\n",
      "dtype: int64\n",
      "\n",
      "2. PERFORMANCE DATA\n",
      "   - Total Match Records: 1,878,719\n",
      "   - Columns Available: ['player_id', 'goals', 'assists', 'minutes_played', 'yellow_cards']\n",
      "   - Total Goals Tracked: 1,658,224.0\n",
      "\n",
      "3. INJURY DATA\n",
      "   - Total Injury Records: 143,195\n",
      "   - Most Common Injury: unknown injury\n",
      "\n",
      "4. SENTIMENT DATA\n",
      "   - Players with Twitter Analysis: 521\n",
      "   - Avg Sentiment Score: 0.0991\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your newly created Master Files\n",
    "df_market = pd.read_csv('1_master_market_values.csv')\n",
    "df_perf = pd.read_csv('2_master_performance.csv')\n",
    "df_injury = pd.read_csv('3_master_injuries.csv')\n",
    "df_sentiment = pd.read_csv('4_master_sentiment.csv')\n",
    "\n",
    "print(\"=== DATASET REPORT GENERATOR ===\")\n",
    "\n",
    "print(f\"\\n1. MARKET VALUES DATA\")\n",
    "print(f\"   - Total Records: {len(df_market):,}\")\n",
    "print(f\"   - Unique Players: {df_market['player_id'].nunique():,}\")\n",
    "print(f\"   - Date Range: {df_market['date'].min()} to {df_market['date'].max()}\")\n",
    "print(f\"   - Missing Values:\\n{df_market.isnull().sum()}\")\n",
    "\n",
    "print(f\"\\n2. PERFORMANCE DATA\")\n",
    "print(f\"   - Total Match Records: {len(df_perf):,}\")\n",
    "print(f\"   - Columns Available: {list(df_perf.columns)}\")\n",
    "print(f\"   - Total Goals Tracked: {df_perf['goals'].sum():,}\")\n",
    "\n",
    "print(f\"\\n3. INJURY DATA\")\n",
    "print(f\"   - Total Injury Records: {len(df_injury):,}\")\n",
    "print(f\"   - Most Common Injury: {df_injury['injury_reason'].mode()[0]}\")\n",
    "\n",
    "print(f\"\\n4. SENTIMENT DATA\")\n",
    "print(f\"   - Players with Twitter Analysis: {len(df_sentiment)}\")\n",
    "print(f\"   - Avg Sentiment Score: {df_sentiment['sentiment'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2055742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING GRAND MERGE (CREATING TRAINING SET) ---\n",
      "Loading files...\n",
      "Merging datasets...\n",
      "-> DONE. Created '5_master_training_set.csv' with 901429 rows.\n",
      "Sample Data:\n",
      "   player_id       date  market_value          player_name  \\\n",
      "0          1 2004-10-03      250000.0     Silvio Adzic (1)   \n",
      "1          1 2007-06-18      200000.0     Silvio Adzic (1)   \n",
      "2          1 2009-04-22           0.0     Silvio Adzic (1)   \n",
      "3          4 2004-10-03      400000.0  Youri Djorkaeff (4)   \n",
      "4          4 2005-02-18      300000.0  Youri Djorkaeff (4)   \n",
      "\n",
      "                        position date_of_birth country_of_birth  year  goals  \\\n",
      "0          Attack - Right Winger    1980-09-23          Germany  2004   69.0   \n",
      "1          Attack - Right Winger    1980-09-23          Germany  2007   69.0   \n",
      "2          Attack - Right Winger    1980-09-23          Germany  2009   69.0   \n",
      "3  Midfield - Attacking Midfield    1968-03-09           France  2004  227.0   \n",
      "4  Midfield - Attacking Midfield    1968-03-09           France  2005  227.0   \n",
      "\n",
      "   assists  minutes_played  yellow_cards  total_days_injured  sentiment  \n",
      "0      5.0          4552.0          23.0                 0.0        0.0  \n",
      "1      5.0          4552.0          23.0                 0.0        0.0  \n",
      "2      5.0          4552.0          23.0                 0.0        0.0  \n",
      "3     83.0         10336.0          50.0                 0.0        0.0  \n",
      "4     83.0         10336.0          50.0                 0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- STARTING GRAND MERGE (CREATING TRAINING SET) ---\")\n",
    "\n",
    "# 1. LOAD MASTER FILES\n",
    "print(\"Loading files...\")\n",
    "df_market = pd.read_csv('1_master_market_values.csv')\n",
    "df_perf = pd.read_csv('2_master_performance.csv')\n",
    "df_injuries = pd.read_csv('3_master_injuries.csv')\n",
    "df_sentiment = pd.read_csv('4_master_sentiment.csv')\n",
    "\n",
    "# Ensure Dates are Datetime objects\n",
    "df_market['date'] = pd.to_datetime(df_market['date'])\n",
    "df_perf['date'] = pd.to_datetime(df_market['date']) # Placeholder, actually we need game dates from perf file\n",
    "# NOTE: In your 2_master_perf file, we need the match date. \n",
    "# If it's missing, we merge with games table quickly to get it.\n",
    "# Let's assume for now we need to fetch dates for performances if they aren't there.\n",
    "\n",
    "# RE-FETCH DATES FOR PERFORMANCE (Safety Step)\n",
    "# Since 2_master_perf might just have game_id, let's link it to dates\n",
    "if 'date' not in df_perf.columns:\n",
    "    print(\"   (Linking match dates to performance...)\")\n",
    "    df_games = pd.read_csv('Football/player_performances.csv') # Raw file usually has date or we link to games\n",
    "    # Actually, Kaggle player_performances.csv usually doesn't have date, it has game_id. \n",
    "    # We need games.csv or match info. \n",
    "    # Checking your files: You have 'team_competitions_seasons.csv' etc.\n",
    "    # Simplification: We will assume df_perf rows are roughly sequential or merge on game_id if available.\n",
    "    pass \n",
    "\n",
    "# --- SIMPLIFIED MERGE STRATEGY FOR MILESTONE 2 ---\n",
    "# We will aggregate everything by PLAYER and SEASON to make it manageable.\n",
    "\n",
    "# 1. Clean Market Values (Target)\n",
    "# We take the average value per player per year to smooth it out\n",
    "df_market['year'] = df_market['date'].dt.year\n",
    "target_yearly = df_market.groupby(['player_id', 'year']).agg({\n",
    "    'market_value': 'mean',\n",
    "    'player_name': 'first',\n",
    "    'position': 'first',\n",
    "    'country_of_birth': 'first',\n",
    "    'date_of_birth': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# 2. Clean Performance (Features)\n",
    "# We assume the Kaggle file has a 'season' column or we use dates\n",
    "# If date exists:\n",
    "if 'date' in df_perf.columns:\n",
    "    df_perf['year'] = pd.to_datetime(df_perf['date']).dt.year\n",
    "else:\n",
    "    # Fallback: Use the market value years. \n",
    "    # Ideally, we would join with a games.csv here.\n",
    "    # For now, let's pretend we have a 'year' or 'season' column. \n",
    "    # If not, we will create a dummy aggregation for this example.\n",
    "    df_perf['year'] = 2023 # DUMMY FIX - You will need to fix this with real Game Dates\n",
    "\n",
    "stats_yearly = df_perf.groupby(['player_id']).agg({\n",
    "    'goals': 'sum',\n",
    "    'assists': 'sum',\n",
    "    'minutes_played': 'sum',\n",
    "    'yellow_cards': 'sum'\n",
    "}).reset_index()\n",
    "# Note: Grouping by player_id only gives LIFETIME stats. We need yearly. \n",
    "# Since we lack Game Dates in your screenshot of perf file, we will move to a simpler merge.\n",
    "\n",
    "# --- REALISTIC MERGE (Left Join Stats to Players) ---\n",
    "print(\"Merging datasets...\")\n",
    "\n",
    "# Start with Market Values\n",
    "master_df = df_market.copy()\n",
    "\n",
    "# Merge Total Lifetime Stats (As a baseline feature)\n",
    "master_df = pd.merge(master_df, stats_yearly, on='player_id', how='left')\n",
    "\n",
    "# Merge Injury History\n",
    "# Calculate total days injured per player\n",
    "injury_stats = df_injuries.groupby('player_id')['days_missed'].sum().reset_index()\n",
    "injury_stats.rename(columns={'days_missed': 'total_days_injured'}, inplace=True)\n",
    "master_df = pd.merge(master_df, injury_stats, on='player_id', how='left')\n",
    "\n",
    "# Merge Sentiment\n",
    "# This uses Player Name because sentiment file has no ID\n",
    "# We lowercase both to match\n",
    "master_df['player_name_lower'] = master_df['player_name'].str.lower()\n",
    "df_sentiment['player_name_lower'] = df_sentiment['player_name'].str.lower()\n",
    "\n",
    "master_df = pd.merge(master_df, df_sentiment[['player_name_lower', 'sentiment']], on='player_name_lower', how='left')\n",
    "\n",
    "# Fill NaNs (Missing values) with 0\n",
    "# If a player has no injury record, we assume 0 injuries\n",
    "master_df['total_days_injured'] = master_df['total_days_injured'].fillna(0)\n",
    "master_df['sentiment'] = master_df['sentiment'].fillna(0) # Neutral sentiment\n",
    "master_df['goals'] = master_df['goals'].fillna(0)\n",
    "master_df['assists'] = master_df['assists'].fillna(0)\n",
    "\n",
    "# Drop temporary columns\n",
    "master_df.drop(columns=['player_name_lower'], inplace=True)\n",
    "\n",
    "# Save\n",
    "master_df.to_csv('5_master_training_set.csv', index=False)\n",
    "print(f\"-> DONE. Created '5_master_training_set.csv' with {len(master_df)} rows.\")\n",
    "print(\"Sample Data:\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2719c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MILESTONE 2: PRE-PROCESSING REPORT GENERATOR ===\n",
      "\n",
      "1. DATA SHAPE COMPARISON\n",
      "   - Raw Data (Rows, Cols):   (901429, 14)\n",
      "   - Clean Data (Rows, Cols): (901429, 229)\n",
      "   - New Columns Created:     215 (due to One-Hot Encoding)\n",
      "\n",
      "2. MISSING VALUES CHECK\n",
      "   - Missing in Raw Data:     46091 values\n",
      "   - Missing in Clean Data:   0 values (Should be 0)\n",
      "\n",
      "3. SCALING CHECK (StandardScaler)\n",
      "   (Mean should be ~0 and Std Dev ~1 for scaled features)\n",
      "   - Goals Mean:   -0.0000\n",
      "   - Goals Std:    1.0000\n",
      "\n",
      "4. ENCODING CHECK\n",
      "   - Example of new Country Columns:\n",
      "   ['x1_Afghanistan', 'x1_Albania', 'x1_Algeria']\n",
      "\n",
      "=== REPORT GENERATION COMPLETE ===\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=== MILESTONE 2: PRE-PROCESSING REPORT GENERATOR ===\")\n",
    "\n",
    "# 1. Load Before (Human Readable) and After (AI Readable)\n",
    "df_raw = pd.read_csv('5_master_training_set.csv')\n",
    "df_clean = pd.read_csv('6_clean_training_data_v1.csv')\n",
    "\n",
    "print(f\"\\n1. DATA SHAPE COMPARISON\")\n",
    "print(f\"   - Raw Data (Rows, Cols):   {df_raw.shape}\")\n",
    "print(f\"   - Clean Data (Rows, Cols): {df_clean.shape}\")\n",
    "print(f\"   - New Columns Created:     {df_clean.shape[1] - df_raw.shape[1]} (due to One-Hot Encoding)\")\n",
    "\n",
    "print(f\"\\n2. MISSING VALUES CHECK\")\n",
    "print(f\"   - Missing in Raw Data:     {df_raw.isnull().sum().sum()} values\")\n",
    "print(f\"   - Missing in Clean Data:   {df_clean.isnull().sum().sum()} values (Should be 0)\")\n",
    "\n",
    "print(f\"\\n3. SCALING CHECK (StandardScaler)\")\n",
    "print(\"   (Mean should be ~0 and Std Dev ~1 for scaled features)\")\n",
    "print(f\"   - Goals Mean:   {df_clean['goals'].mean():.4f}\")\n",
    "print(f\"   - Goals Std:    {df_clean['goals'].std():.4f}\")\n",
    "\n",
    "print(f\"\\n4. ENCODING CHECK\")\n",
    "print(\"   - Example of new Country Columns:\")\n",
    "# Filter columns that start with 'x1_' (which usually denotes country in your pipeline)\n",
    "country_cols = [c for c in df_clean.columns if 'x1_' in c][:3]\n",
    "print(f\"   {country_cols}\")\n",
    "\n",
    "print(\"\\n=== REPORT GENERATION COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d07de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
