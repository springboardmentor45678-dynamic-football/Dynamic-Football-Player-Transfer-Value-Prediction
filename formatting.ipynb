{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09380e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df =pd.read_csv(\"preprocessed_data.csv\")\n",
    "\n",
    "df.loc[df['clean_sheets'] > 0, 'goals_conceded'] = 0\n",
    "\n",
    "df['goals_conceded'] = (\n",
    "    df['goals_conceded']\n",
    "    .round()\n",
    "    .clip(lower=0, upper=6)\n",
    ")\n",
    "\n",
    "df['goals_conceded'] = np.minimum(\n",
    "    df['goals_conceded'],\n",
    "    df['nb_on_pitch'] * 10\n",
    ")\n",
    "\n",
    "df['clean_sheets'] = (\n",
    "    df['clean_sheets']\n",
    "    .round()\n",
    "    .clip(lower=0, upper=2)\n",
    ")\n",
    "\n",
    "df['clean_sheets'] = np.minimum(\n",
    "    df['clean_sheets'],\n",
    "    df['nb_on_pitch']\n",
    ")\n",
    "\n",
    "# Days missed\n",
    "# -------------------------------\n",
    "df['days_missed'] = df['days_missed'].round().clip(lower=0, upper=200)\n",
    "\n",
    "# -------------------------------\n",
    "# Games missed\n",
    "# -------------------------------\n",
    "df['games_missed'] = df['games_missed'].round().clip(lower=0, upper=5)\n",
    "\n",
    "df.to_csv(\"formatted_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bbfff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log transformation completed (original columns overwritten) and saved as 'log_transformed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"formatted_data.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Columns to log-transform (will overwrite original columns)\n",
    "# -------------------------\n",
    "log_cols = [\n",
    "    'injury_reason_freq',\n",
    "    'competition_name_freq',\n",
    "    'team_name_freq',\n",
    "    'citizenship_freq',\n",
    "    'contract_remaining_days'\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Apply log transformation directly to original columns\n",
    "# -------------------------\n",
    "for col in log_cols:\n",
    "    if col in df.columns:\n",
    "        # Ensure no negative values\n",
    "        df[col] = df[col].clip(lower=0)\n",
    "        # Overwrite with log1p\n",
    "        df[col] = np.log1p(df[col])\n",
    "\n",
    "# -------------------------\n",
    "# Save new dataset\n",
    "# -------------------------\n",
    "df.to_csv(\"log_transformed_data.csv\", index=False)\n",
    "\n",
    "print(\"Log transformation completed (original columns overwritten) and saved as 'log_transformed_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab1e74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features and target scaled correctly (IDs, OHE, binary untouched)\n",
      "✅ Scaler objects saved as 'X_scaler.pkl' and 'y_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib  # for saving scaler objects\n",
    "\n",
    "# -------------------------\n",
    "# 1️⃣ Load dataset\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"formatted_data.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# 2️⃣ Define columns\n",
    "# -------------------------\n",
    "target_col = 'value'\n",
    "\n",
    "id_cols = ['player_id']               # add more IDs if needed\n",
    "name_cols = ['player_name']           # name/text columns\n",
    "\n",
    "# Binary + OHE columns (0/1)\n",
    "binary_ohe_cols = [\n",
    "    col for col in df.columns\n",
    "    if df[col].nunique() == 2 and df[col].dropna().isin([0, 1]).all()\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# 3️⃣ Separate X and y\n",
    "# -------------------------\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# -------------------------\n",
    "# 4️⃣ Select numeric columns to scale\n",
    "# (exclude IDs, names, OHE, binary)\n",
    "# -------------------------\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "scale_cols = [\n",
    "    col for col in num_cols\n",
    "    if col not in id_cols\n",
    "    and col not in name_cols\n",
    "    and col not in binary_ohe_cols\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# 5️⃣ Train-test split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 6️⃣ Scale FEATURES\n",
    "# -------------------------\n",
    "X_scaler = StandardScaler()\n",
    "X_train[scale_cols] = X_scaler.fit_transform(X_train[scale_cols])\n",
    "X_test[scale_cols] = X_scaler.transform(X_test[scale_cols])\n",
    "\n",
    "# -------------------------\n",
    "# 7️⃣ Scale TARGET\n",
    "# -------------------------\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Convert back to Series\n",
    "y_train_scaled = pd.Series(y_train_scaled.flatten(), name=target_col)\n",
    "y_test_scaled = pd.Series(y_test_scaled.flatten(), name=target_col)\n",
    "\n",
    "# -------------------------\n",
    "# 8️⃣ Save scaled datasets\n",
    "# -------------------------\n",
    "X_train.to_csv(\"X_train_scaled.csv\", index=False)\n",
    "X_test.to_csv(\"X_test_scaled.csv\", index=False)\n",
    "y_train_scaled.to_csv(\"y_train_scaled.csv\", index=False)\n",
    "y_test_scaled.to_csv(\"y_test_scaled.csv\", index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 9️⃣ Save scaler objects\n",
    "# -------------------------\n",
    "joblib.dump(X_scaler, \"X_scaler.pkl\")\n",
    "joblib.dump(y_scaler, \"y_scaler.pkl\")\n",
    "\n",
    "print(\"✅ Features and target scaled correctly (IDs, OHE, binary untouched)\")\n",
    "print(\"✅ Scaler objects saved as 'X_scaler.pkl' and 'y_scaler.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "795fdce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.164485976856335\n",
      "RMSE: 2.857356466536217\n",
      "R²: 0.8318692343035163\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# 1️⃣ Load dataset\n",
    "# -------------------------\n",
    "df = pd.read_csv(\"formatted_data.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# 2️⃣ Drop ID and name columns\n",
    "# -------------------------\n",
    "cols_to_drop = [\"player_id\", \"player_name\"]\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "\n",
    "# -------------------------\n",
    "# 3️⃣ Define target and features\n",
    "# -------------------------\n",
    "target_col = \"value\"\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[target_col]).select_dtypes(include=['number'])\n",
    "\n",
    "# -------------------------\n",
    "# 4️⃣ Train-test split\n",
    "# -------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 5️⃣ Scale numeric features\n",
    "# -------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# -------------------------\n",
    "# 6️⃣ Train Linear Regression\n",
    "# -------------------------\n",
    "model = LinearRegression(n_jobs=-1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# 7️⃣ Predict on test set\n",
    "# -------------------------\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# -------------------------\n",
    "# 8️⃣ Evaluate model\n",
    "# -------------------------\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e51090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
