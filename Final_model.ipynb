{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywCratGNXO1K",
        "outputId": "798eab49-3d97-47c2-ccef-c06097e73543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset loaded: (50000, 161)\n",
            "After cleaning: (48693, 151)\n",
            "Train: (29215, 150)\n",
            "Validation: (9739, 150)\n",
            "Test: (9739, 150)\n",
            "\n",
            "================ RANDOM FOREST =================\n",
            "RF CV RMSE (Train): 3963221.223524092\n",
            "RF Validation RMSE: 3751508.910542535\n",
            "RF Validation R² : 0.7853036336011671\n",
            "RF Test RMSE: 2451479.6815557266\n",
            "RF Test R² : 0.8962854123091065\n",
            "\n",
            "Selected RF Features: 32\n",
            "['current_club_id', 'contract_expires', 'player_agent_id', 'height', 'position_Attack - Centre-Forward', 'team_id', 'outfitter_adidas', 'position_Midfield - Attacking Midfield', 'minutes_played', 'outfitter_Nike', 'outfitter_Skechers', 'position_Attack - Right Winger', 'days_missed', 'goals', 'on_loan_from_club_id', 'position_Attack - Left Winger', 'season_name_x', 'main_position_Attack', 'games_missed', 'position_Midfield - Defensive Midfield', 'position_Midfield - Central Midfield', 'foot_left', 'nb_on_pitch', 'season_name_y_24/25', 'subed_in', 'assists', 'foot_both', 'main_position_Midfield', 'nb_in_group', 'position_Defender - Centre-Back', 'foot_right', 'outfitter_Under Armour']\n",
            "\n",
            "================ LIGHTGBM =================\n",
            "LGB CV RMSE (Train): 4029378.6175749935\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1852\n",
            "[LightGBM] [Info] Number of data points in the train set: 29215, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 2009684.494267\n",
            "LGB Validation RMSE: 3820954.2919327887\n",
            "LGB Validation R² : 0.777281437598782\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016639 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1921\n",
            "[LightGBM] [Info] Number of data points in the train set: 38954, number of used features: 32\n",
            "[LightGBM] [Info] Start training from score 2017472.018278\n",
            "LGB Test RMSE: 3081990.7466744767\n",
            "LGB Test R² : 0.836074729120997\n",
            "\n",
            "✔ ALL MODELS AND FEATURES SAVED SUCCESSFULLY\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMPLETE END-TO-END ML PIPELINE\n",
        "# Train → Validate → Test + Cross Validation\n",
        "# Models: Random Forest + LightGBM (RF Feature Selection)\n",
        "# ============================================================\n",
        "\n",
        "# ----------------------------\n",
        "# 0. IMPORTS\n",
        "# ----------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, time, joblib, warnings\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "import lightgbm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ----------------------------\n",
        "# 1. LOAD DATA\n",
        "# ----------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/MyDrive/datasets_4/\"\n",
        "df = pd.read_csv(path + \"master_file2_preprocessed_small.csv\")\n",
        "\n",
        "print(\"Dataset loaded:\", df.shape)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. FEATURE ENGINEERING (AS PER YOUR INPUT)\n",
        "# ----------------------------\n",
        "if \"date_of_birth\" in df.columns:\n",
        "    df[\"date_of_birth\"] = pd.to_datetime(df[\"date_of_birth\"], errors=\"coerce\")\n",
        "    df[\"age\"] = datetime.now().year - df[\"date_of_birth\"].dt.year\n",
        "\n",
        "if \"injury_reason\" in df.columns:\n",
        "    df[\"is_injured\"] = df[\"injury_reason\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
        "\n",
        "if (\"goals\" in df.columns) and (\"appearances\" in df.columns):\n",
        "    df[\"goals_per_match\"] = df[\"goals\"] / (df[\"appearances\"] + 1)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. CLEANING\n",
        "# ----------------------------\n",
        "TARGET = \"value\"\n",
        "df = df.dropna(subset=[TARGET])\n",
        "\n",
        "drop_cols = [\n",
        "    \"player_id\", \"date_unix\", \"Unnamed: 0\",\n",
        "    \"text\", \"tweet_date\", \"game_date\",\n",
        "    \"player_name_y\"\n",
        "]\n",
        "\n",
        "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
        "df = df.dropna(axis=1, how=\"all\")\n",
        "\n",
        "print(\"After cleaning:\", df.shape)\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# ----------------------------\n",
        "# 4. TRAIN / VALIDATION / TEST SPLIT (60 / 20 / 20)\n",
        "# ----------------------------\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Validation:\", X_val.shape)\n",
        "print(\"Test:\", X_test.shape)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. IMPUTATION (NUMERIC)\n",
        "# ----------------------------\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "\n",
        "X_train_imp = imputer.fit_transform(X_train)\n",
        "X_val_imp   = imputer.transform(X_val)\n",
        "X_test_imp  = imputer.transform(X_test)\n",
        "X_full_imp  = imputer.fit_transform(X_train_full)\n",
        "\n",
        "# ============================================================\n",
        "# 6. RANDOM FOREST (BASE MODEL + CV)\n",
        "# ============================================================\n",
        "print(\"\\n================ RANDOM FOREST =================\")\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ---- Cross Validation (Train only)\n",
        "rf_cv_rmse = -cross_val_score(\n",
        "    rf, X_train_imp, y_train,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    cv=cv, n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"RF CV RMSE (Train):\", rf_cv_rmse.mean())\n",
        "\n",
        "# ---- Train\n",
        "rf.fit(X_train_imp, y_train)\n",
        "\n",
        "# ---- Validation\n",
        "y_val_rf = rf.predict(X_val_imp)\n",
        "print(\"RF Validation RMSE:\", np.sqrt(mean_squared_error(y_val, y_val_rf)))\n",
        "print(\"RF Validation R² :\", r2_score(y_val, y_val_rf))\n",
        "\n",
        "# ---- Final Train (Train + Validation)\n",
        "rf.fit(X_full_imp, y_train_full)\n",
        "\n",
        "# ---- Test\n",
        "y_test_rf = rf.predict(X_test_imp)\n",
        "print(\"RF Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_rf)))\n",
        "print(\"RF Test R² :\", r2_score(y_test, y_test_rf))\n",
        "\n",
        "# ============================================================\n",
        "# 7. RF FEATURE SELECTION\n",
        "# ============================================================\n",
        "rf_importance = pd.Series(\n",
        "    rf.feature_importances_,\n",
        "    index=feature_names\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "cumulative = rf_importance.cumsum()\n",
        "selected_features = cumulative[cumulative <= 0.95].index.tolist()\n",
        "\n",
        "if len(selected_features) < 20:\n",
        "    selected_features = rf_importance.head(30).index.tolist()\n",
        "\n",
        "print(\"\\nSelected RF Features:\", len(selected_features))\n",
        "print(selected_features)\n",
        "\n",
        "# Reduce feature matrices\n",
        "idx_map = {f: i for i, f in enumerate(feature_names)}\n",
        "sel_idx = [idx_map[f] for f in selected_features]\n",
        "\n",
        "X_train_sel = X_train_imp[:, sel_idx]\n",
        "X_val_sel   = X_val_imp[:, sel_idx]\n",
        "X_test_sel  = X_test_imp[:, sel_idx]\n",
        "X_full_sel  = X_full_imp[:, sel_idx]\n",
        "\n",
        "# ============================================================\n",
        "# 8. LIGHTGBM (RF-SELECTED FEATURES + CV)\n",
        "# ============================================================\n",
        "print(\"\\n================ LIGHTGBM =================\")\n",
        "\n",
        "lgb = LGBMRegressor(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=12,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_samples=10,\n",
        "    objective=\"regression\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# ---- Cross Validation (Train only)\n",
        "lgb_cv_rmse = -cross_val_score(\n",
        "    lgb, X_train_sel, y_train,\n",
        "    scoring=\"neg_root_mean_squared_error\",\n",
        "    cv=cv, n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"LGB CV RMSE (Train):\", lgb_cv_rmse.mean())\n",
        "\n",
        "# ---- Train\n",
        "lgb.fit(X_train_sel, y_train)\n",
        "\n",
        "# ---- Validation\n",
        "y_val_lgb = lgb.predict(X_val_sel)\n",
        "print(\"LGB Validation RMSE:\", np.sqrt(mean_squared_error(y_val, y_val_lgb)))\n",
        "print(\"LGB Validation R² :\", r2_score(y_val, y_val_lgb))\n",
        "\n",
        "# ---- Final Train (Train + Validation)\n",
        "lgb.fit(\n",
        "    X_full_sel, y_train_full,\n",
        "    eval_set=[(X_test_sel, y_test)],\n",
        "    eval_metric=\"rmse\",\n",
        "    callbacks=[lightgbm.early_stopping(50, verbose=False)]\n",
        ")\n",
        "\n",
        "# ---- Test\n",
        "y_test_lgb = lgb.predict(X_test_sel)\n",
        "print(\"LGB Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_test_lgb)))\n",
        "print(\"LGB Test R² :\", r2_score(y_test, y_test_lgb))\n",
        "\n",
        "# ============================================================\n",
        "# 9. SAVE MODELS & FEATURES\n",
        "# ============================================================\n",
        "models_dir = path + \"models_final/\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "joblib.dump(rf, models_dir + \"random_forest_final.joblib\")\n",
        "joblib.dump(lgb, models_dir + \"lightgbm_rf_selected_final.joblib\")\n",
        "\n",
        "pd.DataFrame({\n",
        "    \"feature\": selected_features,\n",
        "    \"rf_importance\": rf_importance[selected_features].values\n",
        "}).to_csv(models_dir + \"rf_selected_features.csv\", index=False)\n",
        "\n",
        "print(\"\\n✔ ALL MODELS AND FEATURES SAVED SUCCESSFULLY\")\n"
      ]
    }
  ]
}